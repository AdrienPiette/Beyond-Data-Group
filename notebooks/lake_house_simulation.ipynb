{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lake House Simulation\n",
    "\n",
    "This notebook simulates a data lake house by loading multiple CSV files into a SQLite database. The data includes absence types, absences, contract basis, postcodes, salary statements, and work plans. The notebook demonstrates how to create database tables, inspect their structure, and query the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Table 'absence_type' créée avec succès\n",
      "✅ Table 'absence' créée avec succès\n",
      "✅ Table 'contract_basis' créée avec succès\n",
      "✅ Table 'post_code' créée avec succès\n",
      "✅ Table 'salary_statement' créée avec succès\n",
      "✅ Table 'work_plan' créée avec succès\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell imports CSV files into a SQLite database. It performs the following steps:\n",
    "1. Reads multiple CSV files into a dictionary of pandas DataFrames.\n",
    "2. Connects to a SQLite database (or creates one if it doesn't exist).\n",
    "3. Cleans column names by stripping whitespace, converting to lowercase, and replacing spaces with underscores.\n",
    "4. Writes each DataFrame to a corresponding table in the SQLite database, replacing the table if it already exists.\n",
    "5. Closes the database connection after all tables are created.\n",
    "\"\"\"\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Fichiers déjà lus dans le dictionnaire\n",
    "csv_files = {\n",
    "    \"absence_type\": pd.read_csv(\n",
    "        r\"C:\\Users\\pieta\\OneDrive\\Bureau\\Beyond Data Group\\Beyond-Data-Group\\csv\\Absence_Type.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"absence\": pd.read_csv(\n",
    "        r\"C:\\Users\\pieta\\OneDrive\\Bureau\\Beyond Data Group\\Beyond-Data-Group\\csv\\ABSENCES.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"contract_basis\": pd.read_csv(\n",
    "        r\"C:\\Users\\pieta\\OneDrive\\Bureau\\Beyond Data Group\\Beyond-Data-Group\\csv\\CONTRACT_BASIS.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"post_code\": pd.read_csv(\n",
    "        r\"C:\\Users\\pieta\\OneDrive\\Bureau\\Beyond Data Group\\Beyond-Data-Group\\csv\\POSTCODES.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"salary_statement\": pd.read_csv(\n",
    "        r\"C:\\Users\\pieta\\OneDrive\\Bureau\\Beyond Data Group\\Beyond-Data-Group\\csv\\SALARY_STATEMENT.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"work_plan\": pd.read_csv(\n",
    "        r\"C:\\Users\\pieta\\OneDrive\\Bureau\\Beyond Data Group\\Beyond-Data-Group\\csv\\WORK_PLAN.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Connexion à la base SQLite\n",
    "conn = sqlite3.connect(\"fabric_sim.db\")\n",
    "\n",
    "for table_name, df in csv_files.items():\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "    df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    print(f\"✅ Table '{table_name}' créée avec succès\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in table 'absence_type':\n",
      "['type_absence', 'type_absence_fr']\n",
      "Columns in table 'absence':\n",
      "['firm_id', 'department_id', 'category_id', 'person_id', 'year', 'quarter', 'month', 'date', 'period', 'qty_illness_days', 'qty_z0_days', 'qty_z1_days', 'qty_z2_days', 'qty_z3_days', 'qty_p0_days', 'qty_p1_days', 'qty_p2_days', 'qty_p3_days', 'qty_a1_days', 'qty_a2_days', 'freq_z0_days', 'freq_z1_days', 'freq_z2_days', 'freq_z3_daqs', 'freq_p0_days', 'freq_p1_days', 'freq_p2_days', 'freq_p3_days', 'freq_a1_days', 'freq_a2_days', 'qty_days_worked', 'qty_working_days']\n",
      "Columns in table 'contract_basis':\n",
      "['contract_zip_code', 'firm_id', 'department_id', 'category_id', 'person_id', 'contract_start_date', 'contract_end_date', 'company_start_date', 'birth_date', 'contract_terminatio_reason', 'gender', 'nationality', 'contract_type']\n",
      "Columns in table 'post_code':\n",
      "['postcode', 'region_code', 'region']\n",
      "Columns in table 'salary_statement':\n",
      "['fdcp', 'gross_salary', 'net_salary', 'gross_salary_108', 'period']\n",
      "Columns in table 'work_plan':\n",
      "['fdcp', 'valid_from', 'valid_to', 'working_days_per_week', 'nace_code', 'nace_description']\n"
     ]
    }
   ],
   "source": [
    "def print_table_columns(*table_names):\n",
    "    \"\"\"\n",
    "    Prints the column names of the specified tables in the SQLite database.\n",
    "\n",
    "    Parameters:\n",
    "    *table_names (str): Names of the tables whose column names are to be printed.\n",
    "\n",
    "    The function connects to the SQLite database 'fabric_sim.db', retrieves the column\n",
    "    information for each specified table using the PRAGMA table_info command, and prints\n",
    "    the column names for each table. The database connection is closed after the operation.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(\"fabric_sim.db\")\n",
    "    for table_name in table_names:\n",
    "        query = f\"PRAGMA table_info({table_name})\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        print(f\"Columns in table '{table_name}':\")\n",
    "        print(result[\"name\"].tolist())\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print_table_columns(\n",
    "    \"absence_type\",\n",
    "    \"absence\",\n",
    "    \"contract_basis\",\n",
    "    \"post_code\",\n",
    "    \"salary_statement\",\n",
    "    \"work_plan\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type_absence', 'type_absence_fr']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell demonstrates how to read a specific table from the SQLite database into a pandas DataFrame.\n",
    "\n",
    "Steps:\n",
    "1. Connects to the SQLite database 'fabric_sim.db'.\n",
    "2. Reads the entire 'absence_type' table into a pandas DataFrame using an SQL SELECT query.\n",
    "3. Prints the column names of the DataFrame as a list.\n",
    "\n",
    "The database connection remains open after the operation.\n",
    "\"\"\"\n",
    "\n",
    "# Example of reading a specific table\n",
    "conn = sqlite3.connect(\"fabric_sim.db\")\n",
    "df_abs_type = pd.read_sql(\"SELECT * FROM absence_type\", conn)\n",
    "\n",
    "print(df_abs_type.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
